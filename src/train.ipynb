{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = pd.read_csv(\"../data/train.csv\")\n",
    "test_data = pd.read_csv(\"../data/test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to fit a model on train data\n",
    "def fit_model(train_data, model, columns_to_drop, column_to_train):\n",
    "    # First split the data into features and target\n",
    "    X = train_data.drop(columns=columns_to_drop, axis=1)\n",
    "    y = train_data[column_to_train]\n",
    "    model.fit(X, y)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "\n",
    "# Function to search for the best hyperparameters\n",
    "def search_hyperparameters(\n",
    "    train_data, model, param_grid, columns_to_drop, column_to_train, scoring\n",
    "):\n",
    "    # First split the data into features and target\n",
    "    X = train_data.drop(columns=columns_to_drop, axis=1)\n",
    "    y = train_data[column_to_train]\n",
    "\n",
    "    grid_search = GridSearchCV(\n",
    "        model,\n",
    "        param_grid,\n",
    "        cv=7,\n",
    "        scoring=scoring,\n",
    "        return_train_score=True,\n",
    "        n_jobs=-1,\n",
    "    )\n",
    "    grid_search.fit(X, y)\n",
    "    return grid_search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, recall_score, f1_score\n",
    "\n",
    "\n",
    "# Function to score a model on given data\n",
    "def score_model(data, model, columns_to_drop, column_to_train):\n",
    "    X = data.drop(columns=columns_to_drop, axis=1)\n",
    "    y = data[column_to_train]\n",
    "    predictions = model.predict(X)\n",
    "    accuracy = accuracy_score(y, predictions)\n",
    "    recall = recall_score(y, predictions)\n",
    "    f1 = f1_score(y, predictions)\n",
    "    return f\"Accuracy: {accuracy}, Recall: {recall}, F1: {f1}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "\n",
    "# Function to evaluate the model predictions\n",
    "def evaluate_model(data, model, columns_to_drop, column_to_train):\n",
    "    X = data.drop(columns=columns_to_drop, axis=1)\n",
    "    y = data[column_to_train]\n",
    "    predictions = model.predict(X)\n",
    "    report = classification_report(y, predictions, digits=3)\n",
    "    return report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Gender\n",
       "0    405\n",
       "1    395\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data[\"Gender\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DecisionTreeClassifier score on train data\n",
      "Accuracy: 0.745, Recall: 0.6962025316455697, F1: 0.7294429708222812\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.728     0.793     0.759       405\n",
      "           1      0.766     0.696     0.729       395\n",
      "\n",
      "    accuracy                          0.745       800\n",
      "   macro avg      0.747     0.744     0.744       800\n",
      "weighted avg      0.747     0.745     0.744       800\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Decision Tree Classifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "model = DecisionTreeClassifier(random_state=42, ccp_alpha=0.003)\n",
    "model = fit_model(\n",
    "    train_data, model, columns_to_drop=[\"Gender\"], column_to_train=\"Gender\"\n",
    ")\n",
    "print(\"DecisionTreeClassifier score on train data\")\n",
    "print(\n",
    "    score_model(train_data, model, columns_to_drop=[\"Gender\"], column_to_train=\"Gender\")\n",
    ")\n",
    "print(\n",
    "    evaluate_model(\n",
    "        train_data, model, columns_to_drop=[\"Gender\"], column_to_train=\"Gender\"\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[321  84]\n",
      " [120 275]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "print(\n",
    "    confusion_matrix(\n",
    "        train_data[\"Gender\"], model.predict(train_data.drop(columns=[\"Gender\"]))\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DecisionTreeClassifier score on test data\n",
      "Accuracy: 0.515, Recall: 0.4807692307692308, F1: 0.5076142131979695\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.495     0.552     0.522        96\n",
      "           1      0.538     0.481     0.508       104\n",
      "\n",
      "    accuracy                          0.515       200\n",
      "   macro avg      0.516     0.516     0.515       200\n",
      "weighted avg      0.517     0.515     0.515       200\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"DecisionTreeClassifier score on test data\")\n",
    "print(\n",
    "    score_model(test_data, model, columns_to_drop=[\"Gender\"], column_to_train=\"Gender\")\n",
    ")\n",
    "print(\n",
    "    evaluate_model(\n",
    "        test_data, model, columns_to_drop=[\"Gender\"], column_to_train=\"Gender\"\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters: {'ccp_alpha': 0.001, 'max_depth': 10, 'max_features': None, 'min_samples_leaf': 2, 'min_samples_split': 2}\n"
     ]
    }
   ],
   "source": [
    "# Grid Search for Decision Tree Classifier\n",
    "param_grid = {\n",
    "    \"max_depth\": [2, 5, 7, 10],\n",
    "    \"min_samples_split\": [2, 5, 10, 20],\n",
    "    \"min_samples_leaf\": [1, 2, 5, 10],\n",
    "    \"max_features\": [None, \"sqrt\", \"log2\"],\n",
    "    \"ccp_alpha\": [0.001, 0.003, 0.005, 0.007, 0.009],\n",
    "}\n",
    "decision_tree_grid_search = search_hyperparameters(\n",
    "    train_data,\n",
    "    model,\n",
    "    param_grid,\n",
    "    columns_to_drop=[\"Gender\"],\n",
    "    column_to_train=\"Gender\",\n",
    "    scoring=\"accuracy\",\n",
    ")\n",
    "print(f\"Best parameters: {decision_tree_grid_search.best_params_}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "decision_tree_model_best = fit_model(\n",
    "    train_data,\n",
    "    DecisionTreeClassifier(**decision_tree_grid_search.best_params_, random_state=42),\n",
    "    columns_to_drop=[\"Gender\"],\n",
    "    column_to_train=\"Gender\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Tree accuracy on train data: Accuracy: 0.7975, Recall: 0.7215189873417721, F1: 0.7786885245901639\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.762     0.872     0.813       405\n",
      "           1      0.846     0.722     0.779       395\n",
      "\n",
      "    accuracy                          0.797       800\n",
      "   macro avg      0.804     0.797     0.796       800\n",
      "weighted avg      0.804     0.797     0.796       800\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Score the model on train data\n",
    "decision_tree_best = score_model(\n",
    "    train_data,\n",
    "    decision_tree_model_best,\n",
    "    columns_to_drop=[\"Gender\"],\n",
    "    column_to_train=\"Gender\",\n",
    ")\n",
    "print(f\"Decision Tree accuracy on train data: {decision_tree_best}\")\n",
    "# Evaluate the model predictions\n",
    "print(\n",
    "    evaluate_model(\n",
    "        train_data,\n",
    "        decision_tree_model_best,\n",
    "        columns_to_drop=[\"Gender\"],\n",
    "        column_to_train=\"Gender\",\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Tree accuracy on test data: Accuracy: 0.54, Recall: 0.4326923076923077, F1: 0.4945054945054945\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.516     0.656     0.578        96\n",
      "           1      0.577     0.433     0.495       104\n",
      "\n",
      "    accuracy                          0.540       200\n",
      "   macro avg      0.547     0.544     0.536       200\n",
      "weighted avg      0.548     0.540     0.535       200\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Score the model on test data\n",
    "decision_tree_best = score_model(\n",
    "    test_data,\n",
    "    decision_tree_model_best,\n",
    "    columns_to_drop=[\"Gender\"],\n",
    "    column_to_train=\"Gender\",\n",
    ")\n",
    "print(f\"Decision Tree accuracy on test data: {decision_tree_best}\")\n",
    "# Evaluate the model predictions\n",
    "print(\n",
    "    evaluate_model(\n",
    "        test_data,\n",
    "        decision_tree_model_best,\n",
    "        columns_to_drop=[\"Gender\"],\n",
    "        column_to_train=\"Gender\",\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 365,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 1.0, Recall: 1.0, F1: 1.0\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      1.000     1.000     1.000       405\n",
      "           1      1.000     1.000     1.000       395\n",
      "\n",
      "    accuracy                          1.000       800\n",
      "   macro avg      1.000     1.000     1.000       800\n",
      "weighted avg      1.000     1.000     1.000       800\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "model = RandomForestClassifier(random_state=0)\n",
    "model = fit_model(\n",
    "    train_data,\n",
    "    model,\n",
    "    columns_to_drop=[\"Gender\"],\n",
    "    column_to_train=\"Gender\",\n",
    ")\n",
    "print(\n",
    "    score_model(\n",
    "        train_data,\n",
    "        model,\n",
    "        columns_to_drop=[\"Gender\"],\n",
    "        column_to_train=\"Gender\",\n",
    "    )\n",
    ")\n",
    "print(\n",
    "    evaluate_model(\n",
    "        train_data,\n",
    "        model,\n",
    "        columns_to_drop=[\"Gender\"],\n",
    "        column_to_train=\"Gender\",\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 366,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.525, Recall: 0.4519230769230769, F1: 0.4973544973544973\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.504     0.604     0.550        96\n",
      "           1      0.553     0.452     0.497       104\n",
      "\n",
      "    accuracy                          0.525       200\n",
      "   macro avg      0.529     0.528     0.524       200\n",
      "weighted avg      0.530     0.525     0.523       200\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\n",
    "    score_model(test_data, model, columns_to_drop=[\"Gender\"], column_to_train=\"Gender\")\n",
    ")\n",
    "print(\n",
    "    evaluate_model(\n",
    "        test_data, model, columns_to_drop=[\"Gender\"], column_to_train=\"Gender\"\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 400,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters: {'ccp_alpha': 0.0005, 'max_depth': 3, 'min_samples_leaf': 6, 'n_estimators': 100}\n"
     ]
    }
   ],
   "source": [
    "# Grid Search for Random Forest Classifier\n",
    "params = {\n",
    "    \"n_estimators\": [25, 50, 100, 200, 300, 500],\n",
    "    \"max_depth\": [1, 2, 3],\n",
    "    \"min_samples_leaf\": [2, 4, 6, 8, 10],\n",
    "    \"ccp_alpha\": [0.0001, 0.0003, 0.0005, 0.0007],\n",
    "}\n",
    "random_forest_grid_search = search_hyperparameters(\n",
    "    train_data,\n",
    "    model,\n",
    "    params,\n",
    "    columns_to_drop=[\"Gender\"],\n",
    "    column_to_train=\"Gender\",\n",
    "    scoring=\"accuracy\",\n",
    ")\n",
    "print(f\"Best parameters: {random_forest_grid_search.best_params_}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 401,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_forest_model_best = fit_model(\n",
    "    train_data,\n",
    "    RandomForestClassifier(**random_forest_grid_search.best_params_, random_state=42),\n",
    "    columns_to_drop=[\"Gender\"],\n",
    "    column_to_train=\"Gender\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 402,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest accuracy on train data: Accuracy: 0.6425, Recall: 0.5670886075949367, F1: 0.6103542234332425\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.629     0.716     0.670       405\n",
      "           1      0.661     0.567     0.610       395\n",
      "\n",
      "    accuracy                          0.642       800\n",
      "   macro avg      0.645     0.642     0.640       800\n",
      "weighted avg      0.645     0.642     0.640       800\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Score the model on train data\n",
    "random_forest_best = score_model(\n",
    "    train_data,\n",
    "    random_forest_model_best,\n",
    "    columns_to_drop=[\"Gender\"],\n",
    "    column_to_train=\"Gender\",\n",
    ")\n",
    "print(f\"Random Forest accuracy on train data: {random_forest_best}\")\n",
    "# Evaluate the model predictions\n",
    "print(\n",
    "    evaluate_model(\n",
    "        train_data,\n",
    "        random_forest_model_best,\n",
    "        columns_to_drop=[\"Gender\"],\n",
    "        column_to_train=\"Gender\",\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 404,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest accuracy on test data: Accuracy: 0.525, Recall: 0.4230769230769231, F1: 0.4808743169398907\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.504     0.635     0.562        96\n",
      "           1      0.557     0.423     0.481       104\n",
      "\n",
      "    accuracy                          0.525       200\n",
      "   macro avg      0.531     0.529     0.522       200\n",
      "weighted avg      0.532     0.525     0.520       200\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Score the model on test data\n",
    "random_forest_best = score_model(\n",
    "    test_data,\n",
    "    random_forest_model_best,\n",
    "    columns_to_drop=[\"Gender\"],\n",
    "    column_to_train=\"Gender\",\n",
    ")\n",
    "print(f\"Random Forest accuracy on test data: {random_forest_best}\")\n",
    "# Evaluate the model predictions\n",
    "print(\n",
    "    evaluate_model(\n",
    "        test_data,\n",
    "        random_forest_model_best,\n",
    "        columns_to_drop=[\"Gender\"],\n",
    "        column_to_train=\"Gender\",\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Rating prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(test_data, model, columns_to_drop):\n",
    "    X = test_data.drop(columns=columns_to_drop, axis=1)\n",
    "    return model.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MSE function\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "\n",
    "def mse(y_true, y_pred):\n",
    "    return mean_squared_error(y_true, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RMSE function\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def rmse(y_true, y_pred):\n",
    "    return np.sqrt(mse(y_true, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# R2 function\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "\n",
    "def r2(y_true, y_pred):\n",
    "    return r2_score(y_true, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def score_model_regression(data, model, columns_to_drop, column_to_train):\n",
    "    X = data.drop(columns=columns_to_drop, axis=1)\n",
    "    y = data[column_to_train]\n",
    "    predictions = model.predict(X)\n",
    "    mse_score = mse(y, predictions)\n",
    "    rmse_score = rmse(y, predictions)\n",
    "    r2_score_value = r2(y, predictions)\n",
    "    return f\"MSE: {mse_score}, RMSE: {rmse_score}, R2: {r2_score_value}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scale the data\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaled_train_data = train_data.copy()\n",
    "scaler = StandardScaler()\n",
    "scaled_train_data[[\"Total\", \"UnitPrice\", \"Tax\"]] = scaler.fit_transform(\n",
    "    scaled_train_data[[\"Total\", \"UnitPrice\", \"Tax\"]]\n",
    ")\n",
    "scaled_test_data = test_data.copy()\n",
    "scaled_test_data[[\"Total\", \"UnitPrice\", \"Tax\"]] = scaler.transform(\n",
    "    scaled_test_data[[\"Total\", \"UnitPrice\", \"Tax\"]]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score for Linear Regression Model on train data:\n",
      " MSE: 2.8797175901390606, RMSE: 1.6969730670046184, R2: 0.013497573928445306\n"
     ]
    }
   ],
   "source": [
    "# Linear Regression Model trained on selected features\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "model = LinearRegression()\n",
    "model = fit_model(\n",
    "    scaled_train_data, model, columns_to_drop=[\"Rating\"], column_to_train=\"Rating\"\n",
    ")\n",
    "print(\n",
    "    \"Score for Linear Regression Model on train data:\\n\",\n",
    "    score_model_regression(\n",
    "        scaled_train_data, model, columns_to_drop=[\"Rating\"], column_to_train=\"Rating\"\n",
    "    ),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score for Linear Regression Model on test data:\n",
      " MSE: 3.110187291026073, RMSE: 1.7635723095541256, R2: -0.013816836503707242\n"
     ]
    }
   ],
   "source": [
    "print(\n",
    "    \"Score for Linear Regression Model on test data:\\n\",\n",
    "    score_model_regression(\n",
    "        scaled_test_data, model, columns_to_drop=[\"Rating\"], column_to_train=\"Rating\"\n",
    "    ),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Total', 'Branch_A', 'Branch_B'], dtype='object')"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Select K Best features\n",
    "from sklearn.feature_selection import SelectKBest, f_regression\n",
    "\n",
    "# Get the selected features\n",
    "selected_features = scaled_train_data.drop(columns=\"Rating\", axis=1).columns[\n",
    "    SelectKBest(f_regression, k=3)\n",
    "    .fit(scaled_train_data.drop(columns=\"Rating\", axis=1), scaled_train_data[\"Rating\"])\n",
    "    .get_support()\n",
    "]\n",
    "selected_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score for Linear Regression Model on train data:\n",
      " MSE: 2.900901625588092, RMSE: 1.7032033424075037, R2: 0.0062405767714963645\n"
     ]
    }
   ],
   "source": [
    "# Train a Linear Regression model on the selected features\n",
    "model = LinearRegression()\n",
    "model = fit_model(\n",
    "    scaled_train_data[selected_features.tolist() + [\"Rating\"]],\n",
    "    model,\n",
    "    columns_to_drop=[\"Rating\"],\n",
    "    column_to_train=\"Rating\",\n",
    ")\n",
    "print(\n",
    "    \"Score for Linear Regression Model on train data:\\n\",\n",
    "    score_model_regression(\n",
    "        scaled_train_data[selected_features.tolist() + [\"Rating\"]],\n",
    "        model,\n",
    "        columns_to_drop=[\"Rating\"],\n",
    "        column_to_train=\"Rating\",\n",
    "    ),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score for Linear Regression Model on test data:\n",
      " MSE: 3.0891882498404444, RMSE: 1.75760867369288, R2: -0.00697185274152301\n"
     ]
    }
   ],
   "source": [
    "print(\n",
    "    \"Score for Linear Regression Model on test data:\\n\",\n",
    "    score_model_regression(\n",
    "        scaled_test_data[selected_features.tolist() + [\"Rating\"]],\n",
    "        model,\n",
    "        columns_to_drop=[\"Rating\"],\n",
    "        column_to_train=\"Rating\",\n",
    "    ),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score for Decision Tree Regressor Model on train data:\n",
      " MSE: 0.28866862731018983, RMSE: 0.537278910166954, R2: 0.9011110318083322\n"
     ]
    }
   ],
   "source": [
    "# Decision Tree Regressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "\n",
    "model = DecisionTreeRegressor(random_state=42, ccp_alpha=0.003)\n",
    "model = fit_model(\n",
    "    train_data, model, columns_to_drop=[\"Rating\"], column_to_train=\"Rating\"\n",
    ")\n",
    "print(\n",
    "    \"Score for Decision Tree Regressor Model on train data:\\n\",\n",
    "    score_model_regression(\n",
    "        train_data, model, columns_to_drop=[\"Rating\"], column_to_train=\"Rating\"\n",
    "    ),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score for Decision Tree Regressor Model on test data:\n",
      " MSE: 6.041170552047959, RMSE: 2.4578792793886275, R2: -0.9692191642375512\n"
     ]
    }
   ],
   "source": [
    "print(\n",
    "    \"Score for Decision Tree Regressor Model on test data:\\n\",\n",
    "    score_model_regression(\n",
    "        test_data, model, columns_to_drop=[\"Rating\"], column_to_train=\"Rating\"\n",
    "    ),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters: {'ccp_alpha': 0.0001, 'max_depth': 3, 'max_features': 'sqrt', 'min_samples_leaf': 10, 'min_samples_split': 2}\n"
     ]
    }
   ],
   "source": [
    "# Grid Search for Decision Tree Regressor\n",
    "param_grid = {\n",
    "    \"max_depth\": [3, 5, 8, 10, 15, 20],\n",
    "    \"min_samples_split\": [2, 5, 10, 20],\n",
    "    \"min_samples_leaf\": [1, 2, 5, 10],\n",
    "    \"max_features\": [\"sqrt\", \"log2\"],\n",
    "    \"ccp_alpha\": [0.0001, 0.0002, 0.0003, 0.0004, 0.0005],\n",
    "}\n",
    "decision_tree_grid_search = search_hyperparameters(\n",
    "    train_data,\n",
    "    model,\n",
    "    param_grid,\n",
    "    columns_to_drop=[\"Rating\"],\n",
    "    column_to_train=\"Rating\",\n",
    "    scoring=\"r2\",\n",
    ")\n",
    "print(f\"Best parameters: {decision_tree_grid_search.best_params_}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit the model with the best hyperparameters\n",
    "decision_tree_model_best = fit_model(\n",
    "    train_data,\n",
    "    DecisionTreeRegressor(**decision_tree_grid_search.best_params_, random_state=42),\n",
    "    columns_to_drop=[\"Rating\"],\n",
    "    column_to_train=\"Rating\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Score the model on train data\n",
    "decision_tree_best = score_model_regression(\n",
    "    train_data,\n",
    "    decision_tree_model_best,\n",
    "    columns_to_drop=[\"Rating\"],\n",
    "    column_to_train=\"Rating\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score for Decision Tree Regressor Model on train data:\n",
      " MSE: 2.7979244589968664, RMSE: 1.6726997515982558, R2: 0.04151737787868859\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model predictions\n",
    "print(\n",
    "    \"Score for Decision Tree Regressor Model on train data:\\n\",\n",
    "    decision_tree_best,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Score the model on test data\n",
    "decision_tree_best = score_model_regression(\n",
    "    test_data,\n",
    "    decision_tree_model_best,\n",
    "    columns_to_drop=[\"Rating\"],\n",
    "    column_to_train=\"Rating\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score for Decision Tree Regressor Model on test data:\n",
      " MSE: 3.066196484767474, RMSE: 1.7510558200033126, R2: 0.0005226922330419104\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model predictions\n",
    "print(\n",
    "    \"Score for Decision Tree Regressor Model on test data:\\n\",\n",
    "    decision_tree_best,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
